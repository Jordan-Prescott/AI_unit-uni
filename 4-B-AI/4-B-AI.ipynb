{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount your Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e532b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change current working directory\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/AI/4-B-AI/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check we can see the dataset\n",
    "os.path.isfile('sepal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with a Decision Tree classifier\n",
    "\n",
    "# data preparation steps\n",
    "\n",
    "# Importing the packages we use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading all the observations\n",
    "observations = pd.read_csv('sepal.csv')\n",
    "\n",
    "# Grabbing a copy of the features so we can show the names when plotting the tree\n",
    "features = observations.columns.drop('species').to_numpy()\n",
    "\n",
    "# Shuffling all the observations\n",
    "observations_shuffled = observations.sample(frac=1, random_state=99)\n",
    "\n",
    "# Setting the fraction of observations we will use for testing\n",
    "testing_fraction = 0.25\n",
    "split_index = int(observations_shuffled.shape[0] * testing_fraction)\n",
    "\n",
    "# Splitting into testing observations and training observations (\"horizontal split\")\n",
    "observations_test = observations_shuffled.iloc[:split_index]\n",
    "observations_train = observations_shuffled.iloc[split_index:]\n",
    "\n",
    "# Splitting into testing examples and testing labels (\"vertical split\")\n",
    "test_examples = observations_test.drop(columns='species').to_numpy()\n",
    "test_labels = observations_test['species'].to_numpy()\n",
    "\n",
    "# Splitting into training examples and training labels (\"vertical split\")\n",
    "train_examples = observations_train.drop(columns='species').to_numpy()\n",
    "train_labels = observations_train['species'].to_numpy()\n",
    "\n",
    "# model training and model evaluation steps\n",
    "\n",
    "# Create a Decision Tree model object and set the minimum parent size hyperparameter to 100:\n",
    "model = DecisionTreeClassifier(min_samples_split=100, random_state=99)\n",
    "\n",
    "# Call the model's fitting algorithm, passing in our training examples and training labels\n",
    "model.fit(train_examples, train_labels)\n",
    "\n",
    "# Use the trained model to generate predictions for our testing examples\n",
    "predictions = model.predict(test_examples)\n",
    "\n",
    "# Find the total number of model predictions that matched with the corresponding testing labels\n",
    "correct_predictions = sum(predictions == test_labels)\n",
    "# Calculate the model's accuracy: the fraction of predictions that were correct\n",
    "accuracy = correct_predictions / len(test_labels)\n",
    "# Display the accuracy as a single quantitative measure of overall performance\n",
    "print(\"Accuracy:\", accuracy, \"(or\", round(accuracy*100, 1), \"%)\")\n",
    "\n",
    "# visualise the final generalisation\n",
    "plt.figure()\n",
    "disp = DecisionBoundaryDisplay.from_estimator(model, train_examples)\n",
    "sns.scatterplot(x=train_examples[:, 0], y=train_examples[:, 1], hue=train_labels)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('Decision tree: final generalisation')\n",
    "plt.show()\n",
    "\n",
    "# show a diagram of the resulting tree structure\n",
    "plt.figure()\n",
    "plot_tree(model, feature_names=features.tolist(), class_names=model.classes_.tolist())\n",
    "plt.show()\n",
    "\n",
    "# Show evaluation results graphically\n",
    "plt.figure()\n",
    "plt.plot([100], [accuracy], marker='o', linestyle='-')\n",
    "plt.title('Accuracy vs. minimum parent size for DT')\n",
    "plt.xlabel('Minimum parent size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "########### Hyperparameter investigation\n",
    "\n",
    "# A list of different minimum parent sizes to test\n",
    "min_parent_sizes = list(range(5, 101, 5))\n",
    "\n",
    "# A list to store accuracy scores for each min parent size\n",
    "accuracy_scores = []\n",
    "\n",
    "# this for loop just contains a copy/paste of the original train/test/visualisation code (further up), ...\n",
    "# but with the fit() call adjusted to use the min_parent_size loop iterator, and a final line to add the ...\n",
    "# accuracy result onto the end of the accuracy_scores list we just made above, ready for plotting\n",
    "for min_parent_size in min_parent_sizes:\n",
    "    # (almost all the code in this for loop is copy/pasted from the original example above, see comment above)\n",
    "    \n",
    "    # Create a Decision Tree model object and set the minimum parent size hyperparameter based on our for loop:\n",
    "    model = DecisionTreeClassifier(min_samples_split=min_parent_size, random_state=99)\n",
    "\n",
    "    # Call the model's fitting algorithm, passing in our training examples and training labels\n",
    "    model.fit(train_examples, train_labels)\n",
    "\n",
    "    # Use the trained model to generate predictions for our testing examples\n",
    "    predictions = model.predict(test_examples)\n",
    "\n",
    "    # Find the total number of model predictions that matched with the corresponding testing labels\n",
    "    correct_predictions = sum(predictions == test_labels)\n",
    "    # Calculate the model's accuracy: the fraction of predictions that were correct\n",
    "    accuracy = correct_predictions / len(test_labels)\n",
    "    # Display the accuracy as a single quantitative measure of overall performance\n",
    "    print(\"Accuracy:\", accuracy, \"(or\", round(accuracy*100, 1), \"%)\")\n",
    "    \n",
    "    # visualise the final generalisation\n",
    "    plt.figure()\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(model, train_examples)\n",
    "    sns.scatterplot(x=train_examples[:, 0], y=train_examples[:, 1], hue=train_labels)\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.title('Decision tree: final generalisation')\n",
    "    plt.show()\n",
    "\n",
    "    # show a diagram of the resulting tree structure\n",
    "    plt.figure()\n",
    "    plot_tree(model, feature_names=features.tolist(), class_names=model.classes_.tolist())\n",
    "    plt.show()\n",
    "    \n",
    "    # Add the lastest accuracy score onto the end of our list of results\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "# finally, we copy/paste the code that was supplied to draw the graph (further up)...\n",
    "# and adjust the .plot() call in order to use the two lists we've just built up in the code above\n",
    "    \n",
    "# Show evaluation results graphically (we've just changed the .plot() call to use the two lists we built up in the code above)\n",
    "plt.figure()\n",
    "plt.plot(min_parent_sizes, accuracy_scores, marker='o', linestyle='-')\n",
    "plt.title('Accuracy vs. minimum parent size for DT')\n",
    "plt.xlabel('Minimum parent size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "########### \n",
    "# (the solution shows diagrams of all the trees it builds, and feature space visualisations of the final generalisations...\n",
    "# ...scroll down to the bottom of all the output to see the final graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c692cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# work with a hard-voting ensemble classifier\n",
    "\n",
    "# data preparation steps\n",
    "\n",
    "# Importing the packages we use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading all the observations\n",
    "observations = pd.read_csv('sepal.csv')\n",
    "\n",
    "# Shuffling all the observations\n",
    "observations_shuffled = observations.sample(frac=1, random_state=99)\n",
    "\n",
    "# Setting the fraction of observations we will use for testing\n",
    "testing_fraction = 0.25\n",
    "split_index = int(observations_shuffled.shape[0] * testing_fraction)\n",
    "\n",
    "# Splitting into testing observations and training observations (\"horizontal split\")\n",
    "observations_test = observations_shuffled.iloc[:split_index]\n",
    "observations_train = observations_shuffled.iloc[split_index:]\n",
    "\n",
    "# Splitting into testing examples and testing labels (\"vertical split\")\n",
    "test_examples = observations_test.drop(columns='species').to_numpy()\n",
    "test_labels = observations_test['species'].to_numpy()\n",
    "\n",
    "# Splitting into training examples and training labels (\"vertical split\")\n",
    "train_examples = observations_train.drop(columns='species').to_numpy()\n",
    "train_labels = observations_train['species'].to_numpy()\n",
    "\n",
    "# model training and model evaluation steps\n",
    "\n",
    "# set the details of the classifiers we want to use (all using their default hyperparameters)\n",
    "model1 = KNeighborsClassifier()\n",
    "model2 = GaussianNB()\n",
    "model3 = DecisionTreeClassifier(random_state=99)\n",
    "\n",
    "# Create a hard-voting ensemble composed of a k-NN, NB and DT classifier\n",
    "model = VotingClassifier(estimators=[('knn', model1), ('nb', model2), ('dt', model3)])\n",
    "\n",
    "# Call the model's fitting algorithm, passing in our training examples and training labels\n",
    "model.fit(train_examples, train_labels)\n",
    "\n",
    "# Use the trained model to generate predictions for our testing examples\n",
    "predictions = model.predict(test_examples)\n",
    "\n",
    "# Find the total number of model predictions that matched with the corresponding testing labels\n",
    "correct_predictions = sum(predictions == test_labels)\n",
    "# Calculate the model's accuracy: the fraction of predictions that were correct\n",
    "accuracy = correct_predictions / len(test_labels)\n",
    "# Display the accuracy as a single quantitative measure of overall performance\n",
    "print(\"Accuracy:\", accuracy, \"(or\", round(accuracy*100, 1), \"%)\")\n",
    "\n",
    "# visualise the final generalisation\n",
    "plt.figure()\n",
    "disp = DecisionBoundaryDisplay.from_estimator(model, train_examples)\n",
    "sns.scatterplot(x=train_examples[:, 0], y=train_examples[:, 1], hue=train_labels)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('Ensemble: final generalisation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f678ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with a bagging ensemble classifier\n",
    "\n",
    "# data preparation steps\n",
    "\n",
    "# Importing the packages we use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading all the observations\n",
    "observations = pd.read_csv('sepal.csv')\n",
    "\n",
    "# Shuffling all the observations\n",
    "observations_shuffled = observations.sample(frac=1, random_state=99)\n",
    "\n",
    "# Setting the fraction of observations we will use for testing\n",
    "testing_fraction = 0.25\n",
    "split_index = int(observations_shuffled.shape[0] * testing_fraction)\n",
    "\n",
    "# Splitting into testing observations and training observations (\"horizontal split\")\n",
    "observations_test = observations_shuffled.iloc[:split_index]\n",
    "observations_train = observations_shuffled.iloc[split_index:]\n",
    "\n",
    "# Splitting into testing examples and testing labels (\"vertical split\")\n",
    "test_examples = observations_test.drop(columns='species').to_numpy()\n",
    "test_labels = observations_test['species'].to_numpy()\n",
    "\n",
    "# Splitting into training examples and training labels (\"vertical split\")\n",
    "train_examples = observations_train.drop(columns='species').to_numpy()\n",
    "train_labels = observations_train['species'].to_numpy()\n",
    "\n",
    "# model training and model evaluation steps\n",
    "\n",
    "# set the details of the classifier we want to use (default hyperparameters)\n",
    "model_dt = DecisionTreeClassifier(random_state=99)\n",
    "\n",
    "# Create a soft-voting ensemble classifier componsed of 100 DTs, each sampling the training data using bagging\n",
    "model = BaggingClassifier(model_dt, n_estimators=100, random_state=99)\n",
    "\n",
    "# Call the model's fitting algorithm, passing in our training examples and training labels\n",
    "model.fit(train_examples, train_labels)\n",
    "\n",
    "# Use the trained model to generate predictions for our testing examples\n",
    "predictions = model.predict(test_examples)\n",
    "\n",
    "# Find the total number of model predictions that matched with the corresponding testing labels\n",
    "correct_predictions = sum(predictions == test_labels)\n",
    "# Calculate the model's accuracy: the fraction of predictions that were correct\n",
    "accuracy = correct_predictions / len(test_labels)\n",
    "# Display the accuracy as a single quantitative measure of overall performance\n",
    "print(\"Accuracy:\", accuracy, \"(or\", round(accuracy*100, 1), \"%)\")\n",
    "\n",
    "# visualise the final generalisation\n",
    "plt.figure()\n",
    "disp = DecisionBoundaryDisplay.from_estimator(model, train_examples)\n",
    "sns.scatterplot(x=train_examples[:, 0], y=train_examples[:, 1], hue=train_labels)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('Ensemble: final generalisation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53377f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with a random forest classifier\n",
    "\n",
    "# data preparation steps\n",
    "\n",
    "# Importing the packages we use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading all the observations\n",
    "observations = pd.read_csv('sepal.csv')\n",
    "\n",
    "# Shuffling all the observations\n",
    "observations_shuffled = observations.sample(frac=1, random_state=99)\n",
    "\n",
    "# Setting the fraction of observations we will use for testing\n",
    "testing_fraction = 0.25\n",
    "split_index = int(observations_shuffled.shape[0] * testing_fraction)\n",
    "\n",
    "# Splitting into testing observations and training observations (\"horizontal split\")\n",
    "observations_test = observations_shuffled.iloc[:split_index]\n",
    "observations_train = observations_shuffled.iloc[split_index:]\n",
    "\n",
    "# Splitting into testing examples and testing labels (\"vertical split\")\n",
    "test_examples = observations_test.drop(columns='species').to_numpy()\n",
    "test_labels = observations_test['species'].to_numpy()\n",
    "\n",
    "# Splitting into training examples and training labels (\"vertical split\")\n",
    "train_examples = observations_train.drop(columns='species').to_numpy()\n",
    "train_labels = observations_train['species'].to_numpy()\n",
    "\n",
    "# model training and model evaluation steps\n",
    "\n",
    "# Create a random forest classifier\n",
    "model = RandomForestClassifier(random_state=99)\n",
    "\n",
    "# Call the model's fitting algorithm, passing in our training examples and training labels\n",
    "model.fit(train_examples, train_labels)\n",
    "\n",
    "# Use the trained model to generate predictions for our testing examples\n",
    "predictions = model.predict(test_examples)\n",
    "\n",
    "# Find the total number of model predictions that matched with the corresponding testing labels\n",
    "correct_predictions = sum(predictions == test_labels)\n",
    "# Calculate the model's accuracy: the fraction of predictions that were correct\n",
    "accuracy = correct_predictions / len(test_labels)\n",
    "# Display the accuracy as a single quantitative measure of overall performance\n",
    "print(\"Accuracy:\", accuracy, \"(or\", round(accuracy*100, 1), \"%)\")\n",
    "\n",
    "# visualise the final generalisation\n",
    "plt.figure()\n",
    "disp = DecisionBoundaryDisplay.from_estimator(model, train_examples)\n",
    "sns.scatterplot(x=train_examples[:, 0], y=train_examples[:, 1], hue=train_labels)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('Random forest: final generalisation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with a linear regressor\n",
    "\n",
    "# data preparation steps\n",
    "\n",
    "# Importing the packages we use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading all the observations\n",
    "observations = pd.read_csv('sepal_regression.csv')\n",
    "\n",
    "# Shuffling all the observations\n",
    "observations_shuffled = observations.sample(frac=1, random_state=99)\n",
    "\n",
    "# Setting the fraction of observations we will use for testing\n",
    "testing_fraction = 0.25\n",
    "split_index = int(observations_shuffled.shape[0] * testing_fraction)\n",
    "\n",
    "# Splitting into testing observations and training observations (\"horizontal split\")\n",
    "observations_test = observations_shuffled.iloc[:split_index]\n",
    "observations_train = observations_shuffled.iloc[split_index:]\n",
    "\n",
    "# Splitting into testing examples and testing values (\"vertical split\")\n",
    "test_examples = observations_test.drop(columns='petal_length').to_numpy()\n",
    "test_values = observations_test['petal_length'].to_numpy()\n",
    "\n",
    "# Splitting into training examples and training values (\"vertical split\")\n",
    "train_examples = observations_train.drop(columns='petal_length').to_numpy()\n",
    "train_values = observations_train['petal_length'].to_numpy()\n",
    "\n",
    "# model training and model evaluation steps\n",
    "\n",
    "# Create a linear regression model object\n",
    "model = LinearRegression()\n",
    "\n",
    "# Call the model's fitting algorithm, passing in our training examples and training values\n",
    "model.fit(train_examples, train_values)\n",
    "\n",
    "# Use the trained model to generate predictions for our testing examples\n",
    "predictions = model.predict(test_examples)\n",
    "\n",
    "# Find the mean squared error (MSE) between the model's predictions and the testing values\n",
    "mse = ((predictions - test_values) ** 2).mean()\n",
    "# Display the MSE as a single quantitative measure of overall performance\n",
    "print(\"Mean square error (MSE):\", mse)\n",
    "\n",
    "# Prepare our own grid of testing examples to use in visualization\n",
    "x_min = train_examples[:, 0].min() - 1\n",
    "x_max = train_examples[:, 0].max() + 1\n",
    "y_min = train_examples[:, 1].min() - 1\n",
    "y_max = train_examples[:, 1].max() + 1\n",
    "grid_x, grid_y = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "grid_examples = np.c_[grid_x.ravel(), grid_y.ravel()]\n",
    "\n",
    "# Make predictions for each of the examples in the grid\n",
    "grid_predictions = model.predict(grid_examples)\n",
    "grid_predictions = grid_predictions.reshape(grid_x.shape)\n",
    "\n",
    "# Visualise the final generalisation\n",
    "plt.figure()\n",
    "contour = plt.contourf(grid_x, grid_y, grid_predictions, cmap='gray_r', alpha=0.8)\n",
    "plt.colorbar(contour, label='Petal Length')\n",
    "sns.scatterplot(x=train_examples[:, 0], y=train_examples[:, 1], hue=train_values, palette='gray_r', edgecolor='k', legend=False)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('Linear Regression: final generalisation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d6da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with a linear regressor (matrix multiplication)\n",
    "\n",
    "# data preparation steps\n",
    "\n",
    "# Importing the packages we use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Loading all the observations\n",
    "observations = pd.read_csv('sepal_regression.csv')\n",
    "\n",
    "# Shuffling all the observations\n",
    "observations_shuffled = observations.sample(frac=1, random_state=99)\n",
    "\n",
    "# Setting the fraction of observations we will use for testing\n",
    "testing_fraction = 0.25\n",
    "split_index = int(observations_shuffled.shape[0] * testing_fraction)\n",
    "\n",
    "# Splitting into testing observations and training observations (\"horizontal split\")\n",
    "observations_test = observations_shuffled.iloc[:split_index]\n",
    "observations_train = observations_shuffled.iloc[split_index:]\n",
    "\n",
    "# Splitting into testing examples and testing values (\"vertical split\")\n",
    "test_examples = observations_test.drop(columns='petal_length').to_numpy()\n",
    "test_values = observations_test['petal_length'].to_numpy()\n",
    "\n",
    "# Splitting into training examples and training values (\"vertical split\")\n",
    "train_examples = observations_train.drop(columns='petal_length').to_numpy()\n",
    "train_values = observations_train['petal_length'].to_numpy()\n",
    "\n",
    "# model training and model evaluation steps\n",
    "\n",
    "# Create a linear regression model object\n",
    "model = LinearRegression()\n",
    "\n",
    "# Call the model's fitting algorithm, passing in our training examples and training values\n",
    "model.fit(train_examples, train_values)\n",
    "\n",
    "# Use the trained model to generate predictions for our testing examples manually, with a matrix multiply\n",
    "\n",
    "# Add a column of ones to the test examples to account for the intercept\n",
    "test_examples_with_intercept = np.c_[np.ones(test_examples.shape[0]), test_examples]\n",
    "# Grab the model's parameters (coefficients and intercept)\n",
    "params = np.append(model.intercept_, model.coef_)\n",
    "# Calculate the predictions using a single matrix multiply\n",
    "predictions_manual = test_examples_with_intercept @ params\n",
    "\n",
    "# Find the mean squared error (MSE) between the model's predictions and the testing values\n",
    "mse = ((predictions_manual - test_values) ** 2).mean()\n",
    "# Display the MSE as a single quantitative measure of overall performance\n",
    "print(\"Mean square error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with a linear regressor (SGD)\n",
    "\n",
    "# data preparation steps\n",
    "\n",
    "# Importing the packages we use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading all the observations\n",
    "observations = pd.read_csv('sepal_regression.csv')\n",
    "\n",
    "# Shuffling all the observations\n",
    "observations_shuffled = observations.sample(frac=1, random_state=99)\n",
    "\n",
    "# Setting the fraction of observations we will use for testing\n",
    "testing_fraction = 0.25\n",
    "split_index = int(observations_shuffled.shape[0] * testing_fraction)\n",
    "\n",
    "# Splitting into testing observations and training observations (\"horizontal split\")\n",
    "observations_test = observations_shuffled.iloc[:split_index]\n",
    "observations_train = observations_shuffled.iloc[split_index:]\n",
    "\n",
    "# Splitting into testing examples and testing values (\"vertical split\")\n",
    "test_examples = observations_test.drop(columns='petal_length').to_numpy()\n",
    "test_values = observations_test['petal_length'].to_numpy()\n",
    "\n",
    "# Splitting into training examples and training values (\"vertical split\")\n",
    "train_examples = observations_train.drop(columns='petal_length').to_numpy()\n",
    "train_values = observations_train['petal_length'].to_numpy()\n",
    "\n",
    "# model training and model evaluation steps\n",
    "\n",
    "# Create a linear regression (SGD) model object\n",
    "model = SGDRegressor(random_state=99)\n",
    "\n",
    "# Call the model's fitting algorithm, passing in our training examples and training values\n",
    "model.fit(train_examples, train_values)\n",
    "\n",
    "# Use the trained model to generate predictions for our testing examples\n",
    "predictions = model.predict(test_examples)\n",
    "\n",
    "# Find the mean squared error (MSE) between the model's predictions and the testing values\n",
    "mse = ((predictions - test_values) ** 2).mean()\n",
    "# Display the MSE as a single quantitative measure of overall performance\n",
    "print(\"Mean square error (MSE):\", mse)\n",
    "\n",
    "# Prepare our own grid of testing examples to use in visualization\n",
    "x_min = train_examples[:, 0].min() - 1\n",
    "x_max = train_examples[:, 0].max() + 1\n",
    "y_min = train_examples[:, 1].min() - 1\n",
    "y_max = train_examples[:, 1].max() + 1\n",
    "grid_x, grid_y = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "grid_examples = np.c_[grid_x.ravel(), grid_y.ravel()]\n",
    "\n",
    "# Make predictions for each of the examples in the grid\n",
    "grid_predictions = model.predict(grid_examples)\n",
    "grid_predictions = grid_predictions.reshape(grid_x.shape)\n",
    "\n",
    "# Visualise the final generalisation\n",
    "plt.figure()\n",
    "contour = plt.contourf(grid_x, grid_y, grid_predictions, cmap='gray_r', alpha=0.8)\n",
    "plt.colorbar(contour, label='Petal Length')\n",
    "sns.scatterplot(x=train_examples[:, 0], y=train_examples[:, 1], hue=train_values, palette='gray_r', edgecolor='k', legend=False)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.title('Linear Regression (SGD): final generalisation')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
