{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"61e7e165"},"outputs":[],"source":["# mount your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"61e7e165"},{"cell_type":"code","execution_count":null,"metadata":{"id":"14e532b0"},"outputs":[],"source":["# change current working directory\n","import os\n","os.chdir('/content/drive/MyDrive/AI/6-B-AI/')"],"id":"14e532b0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"25b4bdca"},"outputs":[],"source":["# check we can see the dataset\n","os.path.exists('FaceDatabaseATT/')"],"id":"25b4bdca"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5e86684b"},"outputs":[],"source":["# train an ANN architecture on the MNIST image dataset using TensorFlow\n","\n","# this is a development of the final code example from the last lab - take some time to review that example\n","# if you haven't already looked at it.\n","\n","# data preparation steps\n","\n","# Importing the packages we use\n","import tensorflow as tf\n","import numpy as np\n","from sklearn.datasets import fetch_openml\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","\n","# Loading the MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n","\n","# Examples and labels\n","examples = mnist['data']\n","labels = mnist['target']\n","\n","# Convert class label strings to integers (required for fast tf operation)\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(labels)\n","\n","# Splitting into testing examples and training examples with corresponding labels\n","train_examples, test_examples, train_labels, test_labels = train_test_split(examples, labels, test_size=0.25, random_state=99)\n","\n","# Standardise our predictive features\n","scaler = StandardScaler()\n","train_examples = scaler.fit_transform(train_examples)\n","test_examples = scaler.transform(test_examples)\n","\n","# model training and model evaluation steps\n","\n","# Re-seed for reproducible results\n","tf.random.set_seed(99)\n","# Build a feed-forward network\n","model = tf.keras.Sequential()\n","# Input layer sizing based on the number of pixels in our images\n","model.add(tf.keras.layers.InputLayer(input_shape=[784]))\n","# Then, keeping things relatively simple/shallow initially, 3 hidden layers with 100 nodes and relu activations\n","model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n","model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n","model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n","# And an output layer using a \"softmax\" function to ensure we get class probabilities that sum to 1\n","model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n","\n","# Compile the model, asking to use cross-entropy as our cost function, and SGD for gradient descent\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n","\n","# Call the model's fitting algorithm, passing in our training examples and training labels, and retaining information about the descent\n","history = model.fit(train_examples, train_labels, epochs=10)\n","\n","# Visualise the gradient descent process\n","plt.figure()\n","plt.plot(history.history['loss'], label='Training Cost')\n","plt.title('Cost')\n","plt.xlabel('Epoch')\n","plt.ylabel('Cost')\n","plt.legend()\n","plt.show()\n","\n","# Use the trained model to generate predictions for our testing examples\n","predictions = model.predict(test_examples)\n","# Convert probabilities to predicted class labels (they are arrays of class probability scores by default)\n","predictions = np.argmax(predictions, axis=1)\n","\n","# Find the total number of model predictions that matched with the corresponding testing labels\n","correct_predictions = sum(predictions == test_labels)\n","# Calculate the model's accuracy: the fraction of predictions that were correct\n","accuracy = correct_predictions / len(test_labels)\n","# Display the accuracy as a single quantitative measure of overall performance\n","print(\"Accuracy:\", accuracy, \"(or\", round(accuracy*100, 1), \"%)\")\n","\n","# We've used familiar code above, but note tf has it's own evaluation helper\n","#model.evaluate(test_examples, test_labels)\n","\n","# WARNING: though this is a relatively small dataset, containing tiny images...\n","# ...the code will still take a while to execute (and may take longer if you...\n","# ...experiment with other architectures...)"],"id":"5e86684b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ROF109mzR5D"},"outputs":[],"source":["# try some feature extraction operations on an image:\n","\n","import matplotlib.pyplot as plt\n","from skimage import io, color, feature, filters, exposure\n","from scipy import ndimage as ndi\n","from skimage.transform import resize\n","import numpy as np\n","\n","# Load the image\n","image = io.imread('peppers.png')\n","print(\"Original image shape:\", image.shape)\n","\n","# Show the colour image\n","plt.imshow(image)\n","plt.title('Original Image')\n","plt.show()\n","\n","# Convert to grayscale\n","gray_image = color.rgb2gray(image)\n","print(\"Grayscale image shape:\", gray_image.shape)\n","\n","# Show the grayscale image\n","plt.imshow(gray_image, cmap='gray')\n","plt.title('Grayscale Image')\n","plt.show()\n","\n","# Convolution with a vertical edge detection filter\n","vertical_filter = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n","edges_vertical = ndi.convolve(gray_image, vertical_filter)\n","\n","# Show the vertical edges\n","plt.imshow(edges_vertical, cmap='gray')\n","plt.title('Vertical Edges')\n","plt.show()\n","\n","# Convolution with a horizontal edge detection filter\n","horizontal_filter = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])\n","edges_horizontal = ndi.convolve(gray_image, horizontal_filter)\n","\n","# Show the horizontal edges\n","plt.imshow(edges_horizontal, cmap='gray')\n","plt.title('Horizontal Edges')\n","plt.show()\n","\n","# Calculate the gradient magnitude\n","edges_magnitude = np.sqrt(edges_vertical**2 + edges_horizontal**2)\n","\n","# Normalize the gradient magnitude to the range [0, 1] for visualization\n","edges_magnitude_normalized = edges_magnitude / np.max(edges_magnitude)\n","\n","# Show the gradient magnitude\n","plt.imshow(edges_magnitude_normalized, cmap='gray')\n","plt.title('Gradient Magnitude')\n","plt.show()\n","\n","# HOG feature extraction and visualization\n","fd, hog_image = feature.hog(gray_image, orientations=8, pixels_per_cell=(16, 16), visualize=True, block_norm='L2')\n","\n","# Show HOG image\n","plt.imshow(hog_image, cmap='gray')\n","plt.title('HOG Features Visualization')\n","plt.show()"],"id":"3ROF109mzR5D"},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFoUUoPZF_iv"},"outputs":[],"source":["# train a model using HOG features on the FaceDatabaseATT dataset\n","\n","# note: here we also work through an example of loading images from individual local files\n","# (in contrast to loading them up from a pre-processed source, as with MNIST previously)\n","# - this is a reusable template that you can apply with other similarly-structured image datasets\n","\n","import os\n","import numpy as np\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.model_selection import train_test_split\n","from skimage import io, transform\n","from skimage.feature import hog\n","import time\n","\n","def extract_hog_features(images, cell_size=(16, 16)):\n","    hog_features = []\n","    for image in images:\n","        # Calculate the number of cells that fit into the image\n","        n_cells_y = image.shape[0] // cell_size[0]  # number of cells vertically\n","        n_cells_x = image.shape[1] // cell_size[1]  # number of cells horizontally\n","\n","        # Set cells_per_block to cover the entire image (simplest lighting treatment)\n","        cells_per_block = (n_cells_y, n_cells_x)\n","\n","        # Compute HOG features (standardising with a single unit L2 norm across the image (which is a single block))\n","        fd = hog(image, orientations=8, pixels_per_cell=cell_size, cells_per_block=cells_per_block, block_norm='L2', visualize=False, channel_axis=None)\n","        hog_features.append(fd)\n","    return np.array(hog_features)\n","\n","# Support reading images from local storage (assuming classes separated by subfolders)\n","def load_images_and_labels(base_dir, target_size=None):\n","    images = []\n","    labels = []\n","    for folder in os.listdir(base_dir):\n","        folder_path = os.path.join(base_dir, folder)\n","        if os.path.isdir(folder_path):\n","            for file in os.listdir(folder_path):\n","                file_path = os.path.join(folder_path, file)\n","                img = io.imread(file_path)\n","                # though we won't use it here, support the option to resize images too\n","                if target_size:\n","                    img = transform.resize(img, target_size)\n","                images.append(img)\n","                labels.append(folder)\n","    return np.array(images), np.array(labels)\n","\n","# load up the AT&T faces dataset\n","base_dir = 'FaceDatabaseATT'\n","images, labels = load_images_and_labels(base_dir)\n","\n","# Extract HOG features from each image\n","hog_examples = extract_hog_features(images, cell_size=(16,16))\n","\n","# Splitting into testing examples and training examples with corresponding labels\n","train_examples, test_examples, train_labels, test_labels = train_test_split(hog_examples, labels, test_size=0.25, random_state=99)\n","\n","# model training and model evaluation steps\n","\n","# Start timing\n","train_start_time = time.time()\n","\n","# Create a NB model object\n","model = GaussianNB()\n","\n","# Call the model's fitting algorithm, passing in our training examples and training labels\n","model.fit(train_examples, train_labels)\n","\n","# Stop timing\n","train_end_time = time.time()\n","\n","# Calculate the elapsed time for training\n","train_time = train_end_time - train_start_time\n","print(\"Training took\", train_time, \"seconds\")\n","\n","# Start timing for prediction\n","predict_start_time = time.time()\n","\n","# Use the trained model to generate predictions for our testing examples\n","predictions = model.predict(test_examples)\n","\n","# Stop timing for prediction\n","predict_end_time = time.time()\n","\n","# Calculate the elapsed time for prediction\n","predict_time = predict_end_time - predict_start_time\n","print(\"Prediction took\", predict_time, \"seconds\")\n","\n","# Find the total number of model predictions that matched with the corresponding testing labels\n","correct_predictions = sum(predictions == test_labels)\n","# Calculate the model's accuracy: the fraction of predictions that were correct\n","accuracy = correct_predictions / len(test_labels)\n","# Display the accuracy as a single quantitative measure of overall performance\n","print(\"Accuracy:\", accuracy, \"(or\", round(accuracy*100, 1), \"%)\")\n","\n","# WARNING: this code will take a while to execute for the first time only...\n","# ... (and may take longer if you experiment with training other models...)"],"id":"yFoUUoPZF_iv"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4OP-28nLZQgD"},"outputs":[],"source":["# train an ANN architecture on the MNIST image dataset using PyTorch\n","\n","# this is a reworking of the TensorFlow example from earlier on, to use PyTorch\n","\n","# Importing the packages we use\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","import numpy as np\n","from sklearn.datasets import fetch_openml\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","\n","# Check if GPU is available and set the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Loading the MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n","examples = mnist['data']\n","labels = mnist['target']\n","\n","# Convert class label strings to integers\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(labels)\n","\n","# Splitting the dataset\n","train_examples, test_examples, train_labels, test_labels = train_test_split(examples, labels, test_size=0.25, random_state=99)\n","\n","# Standardise our predictive features\n","scaler = StandardScaler()\n","train_examples = scaler.fit_transform(train_examples)\n","test_examples = scaler.transform(test_examples)\n","\n","# Re-seed for reproducible results\n","torch.manual_seed(99)\n","\n","# Convert to PyTorch tensors and move them to the device\n","train_examples = torch.tensor(train_examples, dtype=torch.float32).to(device)\n","test_examples = torch.tensor(test_examples, dtype=torch.float32).to(device)\n","train_labels = torch.tensor(train_labels, dtype=torch.long).to(device)\n","test_labels = torch.tensor(test_labels, dtype=torch.long).to(device)\n","\n","# Create DataLoader for batch processing (and set the batch size)\n","train_dataset = TensorDataset(train_examples, train_labels)\n","train_loader = DataLoader(train_dataset, batch_size=64)\n","\n","# model training and model evaluation steps\n","\n","# Build a feed-forward network\n","model = nn.Sequential(\n","    # Input layer sizing based on the number of pixels in our images\n","    nn.Linear(784, 100),\n","    nn.ReLU(),\n","    # Then, keeping things relatively simple/shallow initially, 3 hidden layers with 100 nodes and relu activations\n","    nn.Linear(100, 100),\n","    nn.ReLU(),\n","    nn.Linear(100, 100),\n","    nn.ReLU(),\n","    # And an output layer using a \"softmax\" function to ensure we get class probabilities that sum to 1\n","    nn.Linear(100, 10)\n",").to(device)\n","\n","# Asking to use cross-entropy as our cost function, and SGD for gradient descent\n","cost = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# Call the model's fitting algorithm manually, one bactch at a time, and retaining information about the descent\n","num_epochs = 10\n","model.train()\n","\n","# Initialize a list to store the average loss per epoch\n","epoch_losses = []\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = cost(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    avg_loss = running_loss / len(train_loader)\n","    epoch_losses.append(avg_loss)  # Store the average loss for this epoch\n","    print(\"Epoch\", epoch+1, \"/\", num_epochs, \"Loss:\", avg_loss)\n","\n","# Visualize training loss\n","plt.figure()\n","plt.plot(range(num_epochs), epoch_losses, label='Cost')  # Plot the stored losses\n","plt.title('Training Cost')\n","plt.xlabel('Epoch')\n","plt.ylabel('Cost')\n","plt.legend()\n","plt.show()\n","\n","# Evaluating the model\n","model.eval()\n","with torch.no_grad():\n","    # Ensure test_examples are on the same device as the model\n","    test_examples = test_examples.to(device)\n","    outputs = model(test_examples)\n","    _, predicted = torch.max(outputs, 1)\n","\n","    # Calculate correct predictions\n","    correct_predictions = torch.sum(predicted == test_labels).item()  # Convert to Python number with .item()\n","\n","    # Calculate accuracy\n","    accuracy = correct_predictions / len(test_labels)\n","\n","    # Print the accuracy\n","    print(\"Accuracy:\", accuracy, \"(or\", round(accuracy * 100, 1), \"%)\")"],"id":"4OP-28nLZQgD"}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}